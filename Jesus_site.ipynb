{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "P7lKgtkfmRpD",
        "RrOiDTyGtdMp",
        "5hGMqZTd6GFB"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inefable12/suspect_pza/blob/main/Jesus_site.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>Instalando dependências</font>"
      ],
      "metadata": {
        "id": "P7lKgtkfmRpD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9egm61Nh5_z",
        "outputId": "a2921a2a-d497-4ff2-9461-569aa424f8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Connecting to security.ub\r0% [Connecting to archive.ubuntu.com (91.189.91.38)] [Connecting to security.ub\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.39)] [\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [788 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,286 kB]\n",
            "Get:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [991 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,231 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,992 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,798 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,021 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [957 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,512 kB]\n",
            "Get:24 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n",
            "Fetched 16.0 MB in 5s (3,356 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 77 not upgraded.\n",
            "Need to get 89.8 MB of archives.\n",
            "After this operation, 302 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n",
            "Fetched 89.8 MB in 3s (32.3 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155629 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.2.0-py3-none-any.whl (983 kB)\n",
            "\u001b[K     |████████████████████████████████| 983 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
            "\u001b[K     |████████████████████████████████| 359 kB 52.8 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 52.5 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 59.5 MB/s \n",
            "\u001b[?25hCollecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.5.18.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.2.0)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.2.0 sniffio-1.2.0 trio-0.20.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# install dependencies\n",
        "!apt-get update \n",
        "!apt install chromium-chromedriver \n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin \n",
        "!pip install selenium \n",
        " \n",
        "from google.colab import files\n",
        "from google.colab import output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>Gerando a lista de entradas</font>"
      ],
      "metadata": {
        "id": "RrOiDTyGtdMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aminos = ['A','R','N','D','E','C','G','Q','H','I','L','K','M','F','P','S','Y','T','W','V']\n",
        "posicoes = ['V7','D8','F13','L19','D49','H51','H57','W68','K96','A102','I133','A134','H137','C138','A139']\n",
        "entrada = []\n",
        "for i in range(len(posicoes)):\n",
        "  for j in range(len(aminos)):\n",
        "    if posicoes[0][0] == aminos[j]:\n",
        "      continue\n",
        "    else:\n",
        "      entrada.append(posicoes[i] + aminos[j])"
      ],
      "metadata": {
        "id": "cFczsxJQtkFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>Simulação</font>"
      ],
      "metadata": {
        "id": "VaSlw9hrj5aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  !mkdir /content/Resultados/\n",
        "except:\n",
        "  pass\n",
        "#Criando saida\n",
        "!echo '' > /content/Resultados/Resultados.csv\n"
      ],
      "metadata": {
        "id": "3P6S-Ch9pgi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import libs\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.support import expected_conditions\n",
        "from selenium.webdriver.support.wait import WebDriverWait\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
        "import time\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# webdriver options\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "#!echo 'Mutation;Predicted Outcome;RSA;SST;Phi;Psi;Depth;Distance to Ligand;ΔΔG DynaMut;ΔΔG DynaMut;ΔΔG ENCoM;ΔΔG ENCoM;ΔΔSVib ENCoM;ΔΔSVib ENCoM;ΔΔG mCSM;ΔΔG mCSM;ΔΔG SDM;ΔΔG SDM;Provean;Provean;SNAP2 Score;SNAP2 Score' > /content/Resultados.csv\n",
        "saida = open(\"/content/Resultados/Resultados.csv\",'w')\n",
        "saida.write(\"Mutation;Predicted Outcome;RSA;SST;Phi;Psi;Depth;Distance to Ligand;ΔΔG DynaMut;ΔΔG DynaMut;ΔΔG ENCoM;ΔΔG ENCoM;ΔΔSVib ENCoM;ΔΔSVib ENCoM;ΔΔG mCSM;ΔΔG mCSM;ΔΔG SDM;ΔΔG SDM;Provean;Provean;SNAP2 Score;SNAP2 Score \\n\")\n",
        "entrada\n",
        "try:\n",
        "  !mkdir /content/Resultados/\n",
        "except:\n",
        "  pass\n",
        "for i in range(len(entrada)):\n",
        "  try:\n",
        "    resultados = []\n",
        "    resultados.append(entrada[i])\n",
        "    driver.get('http://biosig.unimelb.edu.au/suspect_pza/submit_prediction')\n",
        "    driver.find_element(By.NAME, 'mutation_single').send_keys(entrada[i])\n",
        "    driver.find_element(By.XPATH, \"/html/body/main/div[2]/div/div/div/form/div/div[2]/div/div[1]/button\").click()\n",
        "    #driver.find_element(By.NAME, 'mutation').send_keys(concatena)\n",
        "    #driver.find_element(By.NAME, 'chain').click()\n",
        "    #driver.find_element(By.NAME, 'chain').send_keys(str(df[\"chain\"][i]))\n",
        "    #driver.find_element(By.XPATH, \"/html/body/div[2]/div[2]/div[2]/div/form/button\").click()\n",
        "    time.sleep(5)\n",
        "    page = driver.page_source\n",
        "\n",
        "    #Predicted Outcome\n",
        "    elemento = page.index('id=\"ppi2Prediction\"')\n",
        "    indice_aux = 40\n",
        "    res = []\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '>'):\n",
        "        for k in range(30):\n",
        "          res.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == '<'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^a-z^A-Z-. ]', '', res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    # RSA\n",
        "    elemento = page.index('RSA: <b id=\"rsa\">')\n",
        "    indice_aux = 17\n",
        "    res = []\n",
        "    for j in range(6):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    # SST\n",
        "    elemento = page.index('<b id=\"sst\">')\n",
        "    indice_aux = 12\n",
        "    res = []\n",
        "    for j in range(7):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    res = re.sub(\"<\", \"\", res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    # PHI\n",
        "    elemento = page.index('<b id=\"phi\">')\n",
        "    indice_aux = 12\n",
        "    res = []\n",
        "    for j in range(6):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    # Psi\n",
        "    elemento = page.index('<b id=\"psi\">')\n",
        "    indice_aux = 12\n",
        "    res = []\n",
        "    for j in range(6):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    # depth\n",
        "    elemento = page.index('<b id=\"depth\">')\n",
        "    indice_aux = 14\n",
        "    res = []\n",
        "    for j in range(6):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    # depth\n",
        "    elemento = page.index('<b id=\"distance_to_ligand\">')\n",
        "    indice_aux = 27\n",
        "    res = []\n",
        "    for j in range(6):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    resultados.append(res)\n",
        "\n",
        "    #PARAMETROS \n",
        "    # ΔΔG DynaMut:\n",
        "    elemento = page.index('ΔΔG DynaMut: ')\n",
        "    indice_aux = 47\n",
        "    res = []\n",
        "    res2 = []\n",
        "    sai = 0\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "    \n",
        "    # ΔΔG ENCoM:\n",
        "    elemento = page.index('ΔΔG ENCoM:')\n",
        "    indice_aux = 52\n",
        "    res = []\n",
        "    res2 = []\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "\n",
        "    #  ΔΔSVib ENCoM\n",
        "    elemento = page.index('<p>ΔΔS<sub>Vib</sub> ')\n",
        "    indice_aux = 58\n",
        "    res = []\n",
        "    res2 = []\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "\n",
        "      # ΔΔG mCSM\n",
        "    elemento = page.index('<p>ΔΔG mCSM: <b')\n",
        "    indice_aux = 43\n",
        "    res = []\n",
        "    res2 = []\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "\n",
        "      # ΔΔG mCSM\n",
        "    elemento = page.index('<p>ΔΔG SDM: <b')\n",
        "    indice_aux = 40\n",
        "    res = []\n",
        "    res2 = []\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "\n",
        "    # Provean\n",
        "    elemento = page.index('<p>Provean: <b ')\n",
        "    indice_aux = 40\n",
        "    res = []\n",
        "    res2 = []\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "\n",
        "  # SNAP2 Score\n",
        "    elemento = page.index('<b id=\"snap2\" ')\n",
        "    indice_aux = 25\n",
        "    res = []\n",
        "    res2 = []\n",
        "    for j in range(15):\n",
        "      res.append(page[elemento+indice_aux+j])\n",
        "    res = ''.join(res)\n",
        "    res = re.sub('[^0-9-.]', '', res)\n",
        "    sai = 0\n",
        "    for j in range(100):\n",
        "      if sai == 1:\n",
        "        break \n",
        "      if(page[elemento+indice_aux+j] == '('):\n",
        "        for k in range(30):\n",
        "          res2.append(page[elemento+indice_aux+j+k+1])\n",
        "          if (page[elemento+indice_aux+j+k+1] == ')'):\n",
        "            sai = 1\n",
        "            break\n",
        "    res2 = ''.join(res2)\n",
        "    res2 = re.sub('[^a-z^A-Z-. ]', '', res2)\n",
        "    resultados.append(res)\n",
        "    resultados.append(res2)\n",
        "\n",
        "    try:\n",
        "      %cd /content/Resultados\n",
        "    except:\n",
        "      pass\n",
        "    URL = \"http://biosig.unimelb.edu.au/suspect_pza/download_pymol_session/\" + entrada[i] + \"/wt.pse\"\n",
        "    !wget \"{URL}\"\n",
        "    URL = \"http://biosig.unimelb.edu.au/suspect_pza/download_pymol_session/\" + entrada[i] + \"/mt.pse\"\n",
        "    !wget \"{URL}\"\n",
        "    !mv wt.pse {entrada[i]}_wild.pse\n",
        "    !mv mt.pse {entrada[i]}_mutant.pse\n",
        "    for j in range(len(resultados)):\n",
        "      saida.write(resultados[j] + ';')\n",
        "    saida.write(\"\\n\")\n",
        "\n",
        "  except:\n",
        "    print(\"Erro na simulação: \" + entrada[i])\n",
        "    continue\n"
      ],
      "metadata": {
        "id": "VKSfZ2iiikDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='red'>Download dos Resultados</font>"
      ],
      "metadata": {
        "id": "5hGMqZTd6GFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SALVANDO OS ARQUIVOS\n",
        "from zipfile import ZipFile\n",
        "import os\n",
        "try:\n",
        "  !rm -R /content/Resultados/*.zip > /dev/null # remove old pdb files\n",
        "except:\n",
        "  pass\n",
        "%cd /content/Resultados/\n",
        "try:\n",
        "  def zipar(directory):\n",
        "\n",
        "      file_paths = []\n",
        "\n",
        "      for root, directories, files in os.walk(directory):\n",
        "          for filename in files:\n",
        "\n",
        "              filepath = os.path.join(root, filename)\n",
        "              file_paths.append(filepath)\n",
        "    \n",
        "\n",
        "      return file_paths        \n",
        "\n",
        "  def main():\n",
        "      directory = '/content/Resultados/'\n",
        "    \n",
        "\n",
        "      file_paths = zipar(directory)\n",
        "\n",
        "      print('Following files will be zipped:')\n",
        "      for file_name in file_paths:\n",
        "          print(file_name)\n",
        "\n",
        "      with ZipFile('Resultados.zip','w') as zip:\n",
        "          for file in file_paths:\n",
        "              zip.write(file)\n",
        "    \n",
        "      print('All files zipped successfully!')        \n",
        "    \n",
        "    \n",
        "  if __name__ == \"__main__\":\n",
        "      main()\n",
        "  files.download('/content/Resultados/' + 'Resultados.zip')\n",
        "except:\n",
        "  print(\"Erro: Pasta vazia.\")"
      ],
      "metadata": {
        "id": "pnCUPbdh6FFR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}